{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df=pd.read_csv('epi_stroma_data.csv')#load csv file to model\n",
    "df1=df.fillna(df)#removes row inclue with null value cell\n",
    "y=df1.drop(['Mean.Layer.1','Mean.Layer.2','Mean.Layer.3','Standard.deviation.Layer.1','Standard.deviation.Layer.2',\n",
    "           'Standard.deviation.Layer.3','Skewness.Layer.1','Skewness.Layer.2','Skewness.Layer.3','Ratio.Layer.1',\n",
    "           'Ratio.Layer.2','Ratio.Layer.3','Min..pixel.value.Layer.1','Min..pixel.value.Layer.2','Min..pixel.value.Layer.3',\n",
    "           'Max..pixel.value.Layer.1','Max..pixel.value.Layer.2','Max..pixel.value.Layer.3','Mean.of.inner.border.Layer.1',\n",
    "           'Mean.of.inner.border.Layer.2','Mean.of.inner.border.Layer.3','Mean.of.outer.border.Layer.1','Mean.of.outer.border.Layer.2',\n",
    "           'Mean.of.outer.border.Layer.3','Border.Contrast.Layer.1','Border.Contrast.Layer.2','Border.Contrast.Layer.3',\n",
    "           'Contrast.to.neighbor.pixels.Layer.1..3.','Contrast.to.neighbor.pixels.Layer.2..3.',\t'Contrast.to.neighbor.pixels.Layer.3..3.',\n",
    "           'Edge.Contrast.of.neighbor.pixels..Prototype..Layer.1..3.','Edge.Contrast.of.neighbor.pixels..Prototype..Layer.2..3.',\n",
    "           'Edge.Contrast.of.neighbor.pixels..Prototype..Layer.3..3.','StdDev..to.neighbor.pixels.Layer.1..3.',\n",
    "           'StdDev..to.neighbor.pixels.Layer.2..3.','StdDev..to.neighbor.pixels.Layer.3..3.','Circular.Mean.Layer.1..R1..User..3..R2..Same...R1...border.',\n",
    "           'Circular.Mean.Layer.2..R1..User..3..R2..Same...R1...border.','Circular.Mean.Layer.3..R1..User..3..R2..Same...R1...border.',\n",
    "           'Circular.StdDev.Layer.1..R1..User..3..R2..Same...R1...border.',\t'Circular.StdDev.Layer.2..R1..User..3..R2..Same...R1...border.',\n",
    "           'Circular.StdDev.Layer.3..R1..User..3..R2..Same...R1...border.','Circular.StdDev.Mean.Layer.1..R1..User..3..R2..Same...R1...border.',\n",
    "           'Circular.StdDev.Mean.Layer.2..R1..User..3..R2..Same...R1...border.','Circular.StdDev.Mean.Layer.3..R1..User..3..R2..Same...R1...border.',\n",
    "           'Mean.Diff..to.neighbors.Layer.1..0.','Mean.Diff..to.neighbors.Layer.2..0.',\t'Mean.Diff..to.neighbors.Layer.3..0.','Mean.Diff..to.neighbors..abs..Layer.1..0.',\n",
    "           'Mean.Diff..to.neighbors..abs..Layer.2..0.','Mean.Diff..to.neighbors..abs..Layer.3..0.',\n",
    "           'Rel..border.to.brighter.objects.Layer.1','Rel..border.to.brighter.objects.Layer.2','Rel..border.to.brighter.objects.Layer.3','Mean.diff..to.scene.Layer.1',\n",
    "           'Mean.diff..to.scene.Layer.2','Mean.diff..to.scene.Layer.3','Ratio.to.scene.Layer.1','Ratio.to.scene.Layer.2','Ratio.to.scene.Layer.3',\n",
    "           'HSI.Transformation.Hue.R.Layer.1.G.Layer.2.B.Layer.3.','Area..Pxl.','Border.length..Pxl.','Length..mu_m.',\n",
    "           'Length.Width','Number.of.pixels','Rel..Border.to.Image.Border','Volume..Pxl.','Width..mu_m.','Asymmetry','Border.index',\n",
    "           'Compactness','Density','Elliptic.Fit','Radius.of.largest.enclosed.ellipse','Radius.of.smallest.enclosing.ellipse',\n",
    "           'Rectangular.Fit','Roundness','Shape.index','Area..excluding.inner.polygons...Pxl.','Area..including.inner.polygons...Pxl.',\n",
    "           'Average.length.of.edges..polygon...Pxl.','Compactness..polygon.','Length.of.longest.edge..polygon...Pxl.','Number.of.edges..polygon.',\n",
    "           'Number.of.inner.objects..polygon.','Perimeter..polygon...Pxl.','Stddev.of.length.of.edges..polygon...Pxl.',\n",
    "           'Mean.of.sub.objects..stddev.Layer.1..1.','Area.of.sub.objects..mean..1...Pxl.','Area.of.sub.objects..stddev..1...Pxl.',\n",
    "           'Density.of.sub.objects..mean..1.','Density.of.sub.objects..stddev..1.','Asymmetry.of.sub.objects..mean..1.','Asymmetry.of.sub.objects..stddev..1.',\n",
    "           'Direction.of.sub.objects..mean..1.','Direction.of.sub.objects..stddev..1.','GLCM.Homogeneity..quick.8.11..Layer.1..all.dir..',\n",
    "           'GLCM.Contrast..quick.8.11..Layer.1..all.dir..','GLCM.Dissimilarity..quick.8.11..Layer.1..all.dir..','GLCM.Entropy..quick.8.11..Layer.1..all.dir..',\n",
    "           'GLCM.Ang..2nd.moment..quick.8.11..Layer.1..all.dir..','GLCM.Mean..quick.8.11..Layer.1..all.dir..','GLCM.StdDev..quick.8.11..Layer.1..all.dir..',\n",
    "           'GLCM.Correlation..quick.8.11..Layer.1..all.dir..','Number.of.sub.objects.Nucleus..1.','Number.of.sub.objects.Dark..1.',\n",
    "           'Area.of.sub.objects.Nucleus..1...Pxl.','Area.of.sub.objects.Dark..1...Pxl.','Rel..area.of.sub.objects.Nucleus..1.','Rel..area.of.sub.objects.Dark..1.',\n",
    "           'Rel..area.of.sub.objects.unclassified..1.'],axis=1)#select target data set from csv file\n",
    "X=df1.drop(['EpiOrStroma'],axis=1)#select two dimentional array\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(X,y , random_state=10)# divide data set into taining and testing\n",
    "import time\n",
    "\n",
    "start=time.time()\n",
    "log_ge=linear_model.LogisticRegression()#create obtect from Logistic regression\n",
    "log_ge.fit(X_train,y_train)#trainng the data set\n",
    "print(time.time()-start)\n",
    "y_pre=log_ge.predict(X_test)#input testing data set to predict \n",
    "#print y_pre\n",
    "print(metrics.accuracy_score(y_pre,y_pre))#calculate accuracy \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "h=0.2\n",
    "#X1=X.values\n",
    "X_plot =X.values[:, :2]#select first two coloum data from X matrics\n",
    "\n",
    "for weights in ['uniform', 'distance']:\n",
    "    # we create an instance of Logistic regression and fit the data.\n",
    "    clf = linear_model.LogisticRegression()\n",
    "    clf.fit(X_plot, y)\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    x_min, x_max = X_plot[:, 0].min() - 1, X_plot[:, 1].max() + 1\n",
    "    y_min, y_max = X_plot[:, 1].min() - 1, X_plot[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X_plot[:, 0], X_plot[:, 1], c=y, cmap=cmap_bold)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.title(\"Logistic Regression\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}